{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07c941ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Core Libraries\n",
    "# =====================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# =====================\n",
    "# Visualization\n",
    "# =====================\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =====================\n",
    "# Preprocessing\n",
    "# =====================\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer, StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# =====================\n",
    "# Model Selection & Tuning\n",
    "# =====================\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# =====================\n",
    "# Regression Models\n",
    "# =====================\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# =====================\n",
    "# Classification Models\n",
    "# =====================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# =====================\n",
    "# Pipelines\n",
    "# =====================\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# =====================\n",
    "# Metrics\n",
    "# =====================\n",
    "from sklearn.metrics import (confusion_matrix, roc_curve, precision_recall_curve,\n",
    "                             roc_auc_score, precision_score,\n",
    "                             recall_score, f1_score , accuracy_score)\n",
    "\n",
    "# =====================\n",
    "# Other Useful Tools\n",
    "# =====================\n",
    "from sklearn.datasets import make_regression\n",
    "from numpy import log1p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ee51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c279f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b26a3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(\"smoking\" ,axis=1)\n",
    "y = data[\"smoking\"]\n",
    "x_train,x_test,y_train,y_test = train_test_split(x  ,y , random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83dcae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lgb', lgb.LGBMClassifier(objective='binary', random_state=42, n_jobs=-1, n_estimators=1000))\n",
    "])\n",
    "\n",
    "# Randomized hyperparameter distribution\n",
    "param_dist = {\n",
    "    'lgb__num_leaves': [31, 50, 70],\n",
    "    'lgb__max_depth': [-1, 10, 20],\n",
    "    'lgb__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'lgb__min_child_samples': [10, 20, 30],\n",
    "    'lgb__subsample': [0.6, 0.8, 1.0],\n",
    "    'lgb__colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV with fewer iterations\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,                # Try only 20 parameter combos\n",
    "    scoring='accuracy',\n",
    "    cv=2,                    # 2-fold CV for speed\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit with early stopping callback passed via fit_params\n",
    "random_search.fit(\n",
    "    x_train, y_train,\n",
    "    lgb__eval_set=[(x_test, y_test)],\n",
    ")\n",
    "\n",
    "# Results\n",
    "print(\"Best params:\", random_search.best_params_)\n",
    "print(\"Best CV accuracy:\", random_search.best_score_)\n",
    "\n",
    "# Evaluate on validation set\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(x_test)\n",
    "print(\"Validation accuracy:\", confusion_matrix(x_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5da6990c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7798254426723596\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb86a9d",
   "metadata": {},
   "source": [
    "Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc3f9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'logreg__C': 0.01, 'logreg__penalty': 'l2', 'logreg__solver': 'liblinear'}\n",
      "Best CV Score: 0.7495526087495735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77     17783\n",
      "           1       0.70      0.73      0.72     14069\n",
      "\n",
      "    accuracy                           0.75     31852\n",
      "   macro avg       0.74      0.74      0.74     31852\n",
      "weighted avg       0.75      0.75      0.75     31852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'logreg__C': [0.01, 0.1, 1, 10, 100],     # Regularization strength\n",
    "    'logreg__penalty': ['l1', 'l2'],          # Penalty type\n",
    "    'logreg__solver': ['liblinear', 'saga']   # Solvers that support l1 & l2\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,                 # 5-fold cross-validation\n",
    "    scoring='accuracy',   # Can also use 'f1', 'roc_auc'\n",
    "    n_jobs=-1,            # Parallel processing\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearch\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Best parameters & score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Score:\", grid_search.best_score_)\n",
    "\n",
    "# Test set performance\n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fbe3ce",
   "metadata": {},
   "source": [
    "tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34026a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\kaggle-datasets\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7534 - loss: 0.4868 - val_accuracy: 0.7642 - val_loss: 0.4671\n",
      "Epoch 2/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7663 - loss: 0.4697 - val_accuracy: 0.7685 - val_loss: 0.4645\n",
      "Epoch 3/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7694 - loss: 0.4655 - val_accuracy: 0.7674 - val_loss: 0.4632\n",
      "Epoch 4/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.7694 - loss: 0.4644 - val_accuracy: 0.7694 - val_loss: 0.4616\n",
      "Epoch 5/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.7713 - loss: 0.4625 - val_accuracy: 0.7698 - val_loss: 0.4603\n",
      "Epoch 6/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7720 - loss: 0.4619 - val_accuracy: 0.7704 - val_loss: 0.4596\n",
      "Epoch 7/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7726 - loss: 0.4612 - val_accuracy: 0.7690 - val_loss: 0.4589\n",
      "Epoch 8/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7726 - loss: 0.4599 - val_accuracy: 0.7705 - val_loss: 0.4585\n",
      "Epoch 9/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7730 - loss: 0.4598 - val_accuracy: 0.7708 - val_loss: 0.4589\n",
      "Epoch 10/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7733 - loss: 0.4595 - val_accuracy: 0.7714 - val_loss: 0.4584\n",
      "Epoch 11/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7726 - loss: 0.4596 - val_accuracy: 0.7711 - val_loss: 0.4586\n",
      "Epoch 12/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7730 - loss: 0.4587 - val_accuracy: 0.7702 - val_loss: 0.4578\n",
      "Epoch 13/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7736 - loss: 0.4582 - val_accuracy: 0.7711 - val_loss: 0.4578\n",
      "Epoch 14/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7743 - loss: 0.4583 - val_accuracy: 0.7709 - val_loss: 0.4573\n",
      "Epoch 15/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7725 - loss: 0.4593 - val_accuracy: 0.7728 - val_loss: 0.4577\n",
      "Epoch 16/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.7739 - loss: 0.4585 - val_accuracy: 0.7718 - val_loss: 0.4576\n",
      "Epoch 17/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.7745 - loss: 0.4578 - val_accuracy: 0.7723 - val_loss: 0.4581\n",
      "Epoch 18/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.7741 - loss: 0.4575 - val_accuracy: 0.7706 - val_loss: 0.4574\n",
      "Epoch 19/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.7747 - loss: 0.4582 - val_accuracy: 0.7718 - val_loss: 0.4575\n",
      "Epoch 20/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7747 - loss: 0.4572 - val_accuracy: 0.7714 - val_loss: 0.4574\n",
      "Epoch 21/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7746 - loss: 0.4575 - val_accuracy: 0.7730 - val_loss: 0.4582\n",
      "Epoch 22/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7743 - loss: 0.4574 - val_accuracy: 0.7708 - val_loss: 0.4576\n",
      "Epoch 23/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7751 - loss: 0.4579 - val_accuracy: 0.7719 - val_loss: 0.4568\n",
      "Epoch 24/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7756 - loss: 0.4570 - val_accuracy: 0.7728 - val_loss: 0.4576\n",
      "Epoch 25/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7750 - loss: 0.4567 - val_accuracy: 0.7715 - val_loss: 0.4571\n",
      "Epoch 26/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7751 - loss: 0.4571 - val_accuracy: 0.7719 - val_loss: 0.4565\n",
      "Epoch 27/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7758 - loss: 0.4577 - val_accuracy: 0.7704 - val_loss: 0.4578\n",
      "Epoch 28/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7756 - loss: 0.4565 - val_accuracy: 0.7735 - val_loss: 0.4584\n",
      "Epoch 29/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7754 - loss: 0.4568 - val_accuracy: 0.7709 - val_loss: 0.4586\n",
      "Epoch 30/30\n",
      "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7753 - loss: 0.4565 - val_accuracy: 0.7722 - val_loss: 0.4568\n",
      "\u001b[1m996/996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 0.7722 - loss: 0.4568\n",
      "Test Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Scale features (important for NN training)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train)\n",
    "X_test = scaler.transform(x_test)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")  # Binary output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=30,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d4bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(hp.Int('units1', 32, 256, step=32),\n",
    "                                    activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "        ),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='smoking_prediction'\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, validation_data=(X_test, y_test), epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bf598fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee461c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3318/3318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 475us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(test) > 0.5).astype(int)\n",
    "# Flatten it\n",
    "y_pred = y_pred.ravel()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ba72c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"smoking\": y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9673d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
