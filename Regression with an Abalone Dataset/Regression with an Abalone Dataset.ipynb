{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with an Abalone Dataset - Improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This notebook aims to predict the age of abalone from physical measurements. The age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope -- a boring and time-consuming task. Other measurements, which are easier to obtain, are used to predict the age. \n",
    "\n",
    "This notebook will follow a structured approach:\n",
    "1. **Exploratory Data Analysis (EDA):** Understand the data and its characteristics.\n",
    "2. **Feature Engineering:** Create new features to improve model performance.\n",
    "3. **Model Selection:** Train and compare different regression models.\n",
    "4. **Hyperparameter Tuning:** Fine-tune the best model.\n",
    "5. **Submission:** Generate the submission file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_log_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Regression with an Abalone Dataset/train.csv')\n",
    "test_df = pd.read_csv('Regression with an Abalone Dataset/test.csv')\n",
    "sample_submission_df = pd.read_csv('Regression with an Abalone Dataset/my_submission.csv')\n",
    "\n",
    "print('Train data shape:', train_df.shape)\n",
    "print('Test data shape:', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names in the provided dataset have some inconsistencies (`Whole weight`, `Whole weight.1`, `Whole weight.2`). Let's rename them to be more descriptive based on the original Abalone dataset description from the UCI repository. The correct names are `Shucked weight`, `Viscera weight`, and `Shell weight`. The target variable is `Rings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns={'Whole weight': 'Whole_weight', \n",
    "                             'Whole weight.1': 'Shucked_weight', \n",
    "                             'Whole weight.2': 'Viscera_weight', \n",
    "                             'Shell weight': 'Shell_weight'}, inplace=True)\n",
    "\n",
    "test_df.rename(columns={'Whole weight': 'Whole_weight', \n",
    "                            'Whole weight.1': 'Shucked_weight', \n",
    "                            'Whole weight.2': 'Viscera_weight', \n",
    "                            'Shell weight': 'Shell_weight'}, inplace=True)\n",
    "\n",
    "# Also, let's add the 'Rings' column to the test set with NaN values for consistency\n",
    "test_df['Rings'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Target Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['Rings'], bins=28, kde=True)\n",
    "plt.title('Distribution of Rings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Numerical Features Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = train_df.select_dtypes(include=np.number).columns.tolist()\n",
    "numerical_features.remove('id')\n",
    "numerical_features.remove('Rings')\n",
    "\n",
    "train_df[numerical_features].hist(bins=20, figsize=(15, 10), layout=(2, 4))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Categorical Feature Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Sex', data=train_df)\n",
    "plt.title('Distribution of Sex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "corr_matrix = train_df[numerical_features + ['Rings']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(df):\n",
    "    # One-hot encode the 'Sex' column\n",
    "    df = pd.get_dummies(df, columns=['Sex'], drop_first=True)\n",
    "    \n",
    "    # Create ratio features\n",
    "    df['crab_area'] = df['Length'] * df['Diameter']\n",
    "    df['approx_density'] = df['Whole_weight'] / (df['crab_area'] * df['Height'])\n",
    "    df['bmi'] = df['Whole_weight'] / (df['Height']**2)\n",
    "    \n",
    "    # Interaction features\n",
    "    df['length_dia_ratio'] = df['Length'] / df['Diameter']\n",
    "    df['length_height_ratio'] = df['Length'] / df['Height']\n",
    "    df['dia_height_ratio'] = df['Diameter'] / df['Height']\n",
    "    df['shell_shuck_ratio'] = df['Shell_weight'] / df['Shucked_weight']\n",
    "\n",
    "    # Replace infinities with NaNs\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    # Water loss\n",
    "    df['water_loss'] = df['Whole_weight'] - df['Shucked_weight'] - df['Viscera_weight'] - df['Shell_weight']\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_featured_df = feature_engineer(train_df.copy())\n",
    "test_featured_df = feature_engineer(test_df.copy())\n",
    "\n",
    "print('Train featured shape:', train_featured_df.shape)\n",
    "print('Test featured shape:', test_featured_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_featured_df.drop(['id', 'Rings'], axis=1)\n",
    "y = train_featured_df['Rings']\n",
    "X_test_final = test_featured_df.drop(['id', 'Rings'], axis=1)\n",
    "\n",
    "# Align columns - crucial for consistent feature sets\n",
    "train_cols = X.columns\n",
    "test_cols = X_test_final.columns\n",
    "\n",
    "missing_in_test = set(train_cols) - set(test_cols)\n",
    "for c in missing_in_test:\n",
    "    X_test_final[c] = 0\n",
    "\n",
    "missing_in_train = set(test_cols) - set(train_cols)\n",
    "for c in missing_in_train:\n",
    "    X[c] = 0\n",
    "\n",
    "X_test_final = X_test_final[train_cols]\n",
    "\n",
    "# Impute any remaining NaNs\n",
    "X.fillna(X.median(), inplace=True)\n",
    "X_test_final.fillna(X_test_final.median(), inplace=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_final_scaled = scaler.transform(X_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "models = {\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    # Predictions can't be negative\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    score = rmsle(y_val, y_pred)\n",
    "    results[name] = score\n",
    "    print(f'{name} RMSLE: {score:.5f}')\n",
    "\n",
    "results_df = pd.DataFrame(list(results.items()), columns=['Model', 'RMSLE']).sort_values('RMSLE')\n",
    "print('\\nModel Comparison:')\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Hyperparameter Tuning (for the best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume XGBoost is the best model based on the above results\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [5, 7, 9],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=xgb, param_distributions=param_grid, \n",
    "                                   n_iter=20, cv=3, verbose=2, random_state=42, \n",
    "                                   n_jobs=-1, scoring='neg_mean_squared_log_error')\n",
    "\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Best parameters found: ', random_search.best_params_)\n",
    "\n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "y_pred_tuned = best_xgb.predict(X_val_scaled)\n",
    "y_pred_tuned[y_pred_tuned < 0] = 0\n",
    "tuned_rmsle = rmsle(y_val, y_pred_tuned)\n",
    "\n",
    "print(f'Tuned XGBoost RMSLE: {tuned_rmsle:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = best_xgb.predict(X_test_final_scaled)\n",
    "final_predictions[final_predictions < 0] = 0\n",
    "\n",
    "# The predictions are float, but the submission requires integers for Rings\n",
    "final_predictions = np.round(final_predictions).astype(int)\n",
    "\n",
    "submission_df = pd.DataFrame({'id': test_df['id'], 'Rings': final_predictions})\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print('Submission file created successfully!')\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
